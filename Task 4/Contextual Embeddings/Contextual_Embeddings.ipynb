{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8bd9b279",
      "metadata": {
        "scrolled": true,
        "id": "8bd9b279"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install nltk transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "091fd99b",
      "metadata": {
        "id": "091fd99b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from transformers import TFDistilBertModel, DistilBertTokenizer, DistilBertConfig\n",
        "import numpy as np\n",
        "import csv\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.mixed_precision import Policy, set_global_policy\n",
        "\n",
        "# Set global policy\n",
        "policy = Policy('mixed_float16')\n",
        "set_global_policy(policy)\n"
      ],
      "metadata": {
        "id": "hBcCtIOYezc1"
      },
      "id": "hBcCtIOYezc1",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRQtcMT2aMOS",
        "outputId": "f6c3efc4-14cc-43eb-cd34-76d0de3b0d53"
      },
      "id": "WRQtcMT2aMOS",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b570fcde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b570fcde",
        "outputId": "165fabdc-1aa4-406f-b5e7-2dd3d8f15eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('brown')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3c0913b1",
      "metadata": {
        "id": "3c0913b1"
      },
      "outputs": [],
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "\n",
        "original_config = DistilBertConfig.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new configuration with reduced hidden size\n",
        "reduced_hidden_size = 64  # Replace with your desired hidden size\n",
        "reduced_num_hidden_layers = 2  # Choose a smaller number\n",
        "reduced_num_attention_heads = 2  # Choose a smaller number\n",
        "new_config = DistilBertConfig(\n",
        "    vocab_size=original_config.vocab_size,\n",
        "    hidden_size=reduced_hidden_size,\n",
        "    num_hidden_layers=reduced_num_hidden_layers,\n",
        "    num_attention_heads=reduced_num_attention_heads,\n",
        ")"
      ],
      "metadata": {
        "id": "RSHWR9c-hDSA"
      },
      "id": "RSHWR9c-hDSA",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = TFDistilBertModel.from_pretrained(model_name, config=new_config, ignore_mismatched_sizes=True)\n",
        "model = TFDistilBertModel.from_pretrained(model_name)\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMotZs_ghGBw",
        "outputId": "344ce821-a2db-4266-fb25-bb27ac1b06cd"
      },
      "id": "XMotZs_ghGBw",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "63833eae",
      "metadata": {
        "id": "63833eae"
      },
      "outputs": [],
      "source": [
        "def embed_words(words):\n",
        "    tokens = tokenizer.batch_encode_plus(words, padding='max_length', truncation=True, return_tensors='tf', max_length=8)\n",
        "    outputs = model(tokens['input_ids'])\n",
        "    embeddings = outputs.last_hidden_state\n",
        "    averaged_embeddings = tf.reduce_mean(embeddings, axis=1)\n",
        "    return averaged_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = r\"/content/drive/MyDrive/Reuters-21578/reuters/reuters/reuters/training\"\n",
        "dataset_dirs = os.listdir(dataset_path)"
      ],
      "metadata": {
        "id": "zvK2TyXqY3bk"
      },
      "id": "zvK2TyXqY3bk",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for i in tqdm(dataset_dirs):\n",
        "    with open(f\"{dataset_path}/{i}\", 'r') as f:\n",
        "        content = f.read()\n",
        "        data.append(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y054Hz54Y9bJ",
        "outputId": "87e232db-8d85-4845-c2ab-2b3cda081653"
      },
      "id": "Y054Hz54Y9bJ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7769/7769 [00:19<00:00, 406.76it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for text in data:\n",
        "  temp_words = word_tokenize(text)\n",
        "  words.append(temp_words)"
      ],
      "metadata": {
        "id": "yHlmyhIy3-uI"
      },
      "id": "yHlmyhIy3-uI",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "\n",
        "words_flattened = list(chain(*words))\n"
      ],
      "metadata": {
        "id": "CzSR7XPHaVUB"
      },
      "id": "CzSR7XPHaVUB",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(words_flattened)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkUueqI_hd6z",
        "outputId": "8edaf912-f257-43ef-90e5-ea2828c64d78"
      },
      "id": "LkUueqI_hd6z",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1135633"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_flattened = [str(element) for element in words_flattened]"
      ],
      "metadata": {
        "id": "f78itPlWjBr6"
      },
      "id": "f78itPlWjBr6",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2suOMEhZTRP9",
        "outputId": "a35ede58-b2dd-4bbc-d471-95c770209d58"
      },
      "id": "2suOMEhZTRP9",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "TensorFlow version: 2.14.0\n",
            "GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.compat.v1.Session(config=config)"
      ],
      "metadata": {
        "id": "uFKsNMdHUXxW"
      },
      "id": "uFKsNMdHUXxW",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "48f40c52",
      "metadata": {
        "id": "48f40c52"
      },
      "outputs": [],
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  embeddings = embed_words(words_flattened[:10000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OASAnv9JjpM5",
        "outputId": "38dabb85-5374-4c43-86ba-c33a05eaa07c"
      },
      "id": "OASAnv9JjpM5",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10000, 768), dtype=float16, numpy=\n",
              "array([[ 0.3096 , -0.1549 ,  0.0838 , ...,  0.1364 ,  0.3267 , -0.1741 ],\n",
              "       [ 0.398  , -0.0443 ,  0.04486, ...,  0.07684,  0.1287 , -0.03717],\n",
              "       [ 0.3171 , -0.06287,  0.2588 , ...,  0.04208,  0.0778 , -0.1112 ],\n",
              "       ...,\n",
              "       [ 0.3506 , -0.0709 ,  0.273  , ...,  0.1061 ,  0.181  , -0.1644 ],\n",
              "       [ 0.171  , -0.1613 ,  0.2006 , ...,  0.14   ,  0.0867 , -0.0689 ],\n",
              "       [ 0.4185 ,  0.0651 ,  0.3293 , ...,  0.0606 ,  0.1231 , -0.08514]],\n",
              "      dtype=float16)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ca00c34f",
      "metadata": {
        "id": "ca00c34f"
      },
      "outputs": [],
      "source": [
        "# Save embeddings and metadata in TSV format\n",
        "tsv_file = 'word_embeddings.tsv'\n",
        "metadata_file = 'metadata.tsv'\n",
        "\n",
        "# Save embeddings\n",
        "np.savetxt(tsv_file, embeddings, delimiter='\\t')\n",
        "\n",
        "# Save metadata\n",
        "with open(metadata_file, 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file, delimiter='\\t')\n",
        "    writer.writerows([[word] for word in words_flattened[:10000]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "36a8031e",
      "metadata": {
        "id": "36a8031e",
        "outputId": "7fe46649-6774-4058-f057-9b12abf86f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "55b0be06",
      "metadata": {
        "id": "55b0be06"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}